{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Wczytujemy surowa baze, filtrujemy dla Polski i zapisujemy do katalogu 'poland/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano przefiltrowane dane do poland/Database to calculate popularity Poland.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_file_path = 'zrodla/Database to calculate popularity.csv' \n",
    "\n",
    "# Wczytanie pełnego pliku CSV do DataFrame\n",
    "full_df = pd.read_csv(full_file_path, sep=',', low_memory=False)\n",
    "\n",
    "# Filtracja danych dla Polski\n",
    "full_df_poland = full_df[full_df['country'] == 'Poland']\n",
    "\n",
    "# Zapis przefiltrowanych danych do nowego pliku CSV\n",
    "output_full_csv_path = 'poland/Database to calculate popularity Poland.csv'\n",
    "full_df_poland.to_csv(output_full_csv_path, index=False)\n",
    "\n",
    "print(\"Zapisano przefiltrowane dane do\", output_full_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytujemy wynikowa baze filtrujemy dla Polski i zapisujemy do katalogu 'poland/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano przefiltrowane dane do poland/Final database Poland.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_file_path = 'zrodla/Final database.csv' \n",
    "\n",
    "# Wczytanie pełnego pliku CSV do DataFrame\n",
    "full_df = pd.read_csv(full_file_path, sep=',', low_memory=False)\n",
    "\n",
    "# Filtracja danych dla Polski\n",
    "full_df_poland = full_df[full_df['Country'] == 'Poland']\n",
    "\n",
    "# Zapis przefiltrowanych danych do nowego pliku CSV\n",
    "output_full_csv_path = 'poland/Final database Poland.csv'\n",
    "full_df_poland.to_csv(output_full_csv_path, index=False)\n",
    "\n",
    "print(\"Zapisano przefiltrowane dane do\", output_full_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak tylko z ciekawosci sprawdzamy ile unikalnych URI jest w wynikowej bazie dla Polski. To nic nie robi wiecej.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba unikalnych 'uri': 5273\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'poland/Final database Poland.csv'\n",
    "data = pd.read_csv(file_path, sep=',', low_memory=False)\n",
    "\n",
    "unique_uris_count = data['Uri'].nunique()\n",
    "\n",
    "print(f\"Liczba unikalnych 'uri': {unique_uris_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W pliku wynikowym w kolumnie Popu_max szukamy ktore utwory w Polsce doszly do miejsca od 1 do 50 i zapisujemy uri tych utworow do tymczasowego pliku 'top50.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plik 'top50.csv' został zapisany w lokalizacji: poland/top50.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Załaduj pełny plik 'Final database Poland.csv' \n",
    "file_path = 'poland/Final database Poland.csv'\n",
    "final_db_poland = pd.read_csv(file_path, sep=',', low_memory=False)\n",
    "\n",
    "# Sortuj dane według kolumny 'Popu_max' w porządku rosnącym\n",
    "sorted_data = final_db_poland.sort_values(by='Popu_max', ascending=True)\n",
    "\n",
    "# Wybierz rekordy, gdzie 'Popu_max' wynosi miedzy 1 a 50\n",
    "top_tracks = sorted_data[sorted_data['Popu_max'].between(1, 50)]\n",
    "\n",
    "# Wyodrębnij kolumnę 'Uri' i zapisz do nowego DataFrame\n",
    "top_tracks_uris = top_tracks[['Uri']].copy()\n",
    "\n",
    "# Zapisz wynikowy DataFrame do pliku CSV\n",
    "output_file_path = 'poland/top50.csv'\n",
    "top_tracks_uris.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Plik 'top50.csv' został zapisany w lokalizacji: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz bierzemy dane z glownej bazy szukajac po 'uri' z pliku top50.csv i tworzymy pojedyncze pliki dla kazdego utworu gdzie mamy posortowane rekordy po dacie. Sprawdzamy czy rekordow jest wiecej niz 10, i tylko takie zostawiamy. Kazdy plik nazywamy jak jego uri i zapisujemy do katalogu 'wyniki_uri/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "popularity_db_path = 'poland/Database to calculate popularity Poland.csv'\n",
    "popularity_db_poland = pd.read_csv(popularity_db_path, low_memory=False)\n",
    "\n",
    "top50_path = 'poland/top50.csv' \n",
    "top50_uris = pd.read_csv(top50_path)\n",
    "\n",
    "# Pętla przez każde 'uri' w pliku\n",
    "for uri in top50_uris['Uri']:\n",
    "    # Filtrowanie rekordów w bazie danych popularności dla danego 'uri'\n",
    "    filtered_data = popularity_db_poland[popularity_db_poland['uri'] == uri].copy()\n",
    "\n",
    "    # Konwersja kolumny 'date' na datetime\n",
    "    filtered_data.loc[:, 'date'] = pd.to_datetime(filtered_data['date'], format='%d/%m/%Y')\n",
    "\n",
    "    # Sortowanie przefiltrowanych danych według 'date'\n",
    "    sorted_filtered_data = filtered_data.sort_values(by='date', ascending=True)\n",
    "\n",
    "    # Sprawdzenie, czy liczba rekordów wynosi co najmniej 10\n",
    "    if len(sorted_filtered_data) >= 10:\n",
    "        # Wyodrębnienie części 'uri'\n",
    "        uri_part = uri.split('/')[-1]\n",
    "\n",
    "        # Zapis przefiltrowanych i posortowanych danych do nowego pliku CSV\n",
    "        output_file_path = f'wyniki_uri/{uri_part}.csv'\n",
    "        sorted_filtered_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"All files have been processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuwamy z katalogu 'wyniki_uri/' pliki z trendem malejacym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pliki z malejącym trendem zostały usunięte.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Ścieżka do katalogu z plikami\n",
    "directory_path = 'wyniki_uri/'\n",
    "\n",
    "# Pętla przez wszystkie pliki w katalogu\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Wczytanie danych z pliku\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Sprawdzenie, czy 'position' generalnie maleje\n",
    "        # W tym przypadku, \"malejące\" oznacza, że średnia różnica między kolejnymi pozycjami jest dodatnia\n",
    "        # Ponieważ im wyższa liczba w 'position', tym niższa pozycja na liście przebojów\n",
    "        # takie rozwiazanie zaproponowal mi chatGPT\n",
    "        if np.mean(np.diff(data['position'])) > 0:\n",
    "            os.remove(file_path)  # Usunięcie pliku\n",
    "\n",
    "print(\"Pliki z malejącym trendem zostały usunięte.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rysujemy wykresy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wykresy zostały wygenerowane i zapisane.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "results_directory = 'wyniki_uri/'\n",
    "images_directory = 'images/'\n",
    "\n",
    "# Pętla przechodząca przez wszystkie pliki CSV w katalogu wyników\n",
    "for filename in os.listdir(results_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Ścieżka do konkretnego pliku CSV\n",
    "        file_path = os.path.join(results_directory, filename)\n",
    "\n",
    "        # Wczytanie danych z pliku CSV\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Konwersja kolumny 'date' na format datetime\n",
    "        data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "\n",
    "        # Rysowanie wykresu liniowego\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Ustawienie kolorów tła i osi\n",
    "        plt.gca().set_facecolor('#1a1a1a')\n",
    "        plt.gca().tick_params(axis='x', colors='lightgray')\n",
    "        plt.gca().tick_params(axis='y', colors='lightgray')\n",
    "        plt.gca().spines['bottom'].set_color('white')\n",
    "        plt.gca().spines['top'].set_color('#1a1a1a')  # Ustawienie na kolor tła, aby ukryć\n",
    "        plt.gca().spines['right'].set_color('#1a1a1a') # Ustawienie na kolor tła, aby ukryć\n",
    "        plt.gca().spines['left'].set_color('white')\n",
    "\n",
    "        # Wykres liniowy\n",
    "        plt.plot(data['date'], data['position'], marker='o', linestyle='-', color='#49f05b')\n",
    "\n",
    "        # Obrócenie etykiet daty o 35 stopni i ustawienie ich koloru\n",
    "        plt.xticks(rotation=35, color='white')\n",
    "        plt.yticks(color='white')\n",
    "\n",
    "        # Odwrócenie osi Y, aby pozycja 1 była na górze\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        # Ograniczenie liczby etykiet daty na osi X do 20, jeśli jest ich więcej\n",
    "        if len(data['date']) > 20:\n",
    "            plt.gca().xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "\n",
    "        plt.ylabel('Pozycja', color='white')\n",
    "\n",
    "        # Dodanie tytułu z informacjami o utworze\n",
    "        title = data['title'].iloc[0] if 'title' in data.columns else \"Brak tytułu\"\n",
    "        artist = data['artist'].iloc[0] if 'artist' in data.columns else \"Brak artysty\"\n",
    "        track = data['track'].iloc[0] if 'track' in data.columns else \"Brak ścieżki\"\n",
    "        plt.title(f'Track: {track}\\nTitle: {title}\\nArtist: {artist}', color='white')\n",
    "\n",
    "        # Zapisanie wykresu\n",
    "        plt.savefig(f'{images_directory}/{filename}.png', facecolor='#1a1a1a')\n",
    "\n",
    "        # Zamykanie wykresu\n",
    "        plt.close()\n",
    "\n",
    "print(\"Wykresy zostały wygenerowane i zapisane.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tu wersja generujaca pdf z linkiem :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reportlab\n",
      "  Obtaining dependency information for reportlab from https://files.pythonhosted.org/packages/44/2c/f09a5abefa8f2b575acfc19ed4536a365ef0432ae3bce94a57a2de9b4f52/reportlab-4.0.8-py3-none-any.whl.metadata\n",
      "  Downloading reportlab-4.0.8-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\konmak\\appdata\\local\\anaconda3\\lib\\site-packages (from reportlab) (9.4.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\konmak\\appdata\\local\\anaconda3\\lib\\site-packages (from reportlab) (4.0.0)\n",
      "Downloading reportlab-4.0.8-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/1.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/1.9 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/1.9 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 9.5 MB/s eta 0:00:00\n",
      "Installing collected packages: reportlab\n",
      "Successfully installed reportlab-4.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pliki PDF zostały wygenerowane i zapisane.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from PIL import Image\n",
    "\n",
    "images_directory = 'images/'\n",
    "pdf_directory = 'pdf/'\n",
    "\n",
    "# Tworzenie katalogu dla PDF-ów, jeśli nie istnieje\n",
    "os.makedirs(pdf_directory, exist_ok=True)\n",
    "\n",
    "# Pętla przechodząca przez wszystkie pliki PNG w katalogu obrazów\n",
    "for filename in os.listdir(images_directory):\n",
    "    if filename.endswith('.png'):\n",
    "        # Ścieżka do obrazu PNG\n",
    "        image_path = os.path.join(images_directory, filename)\n",
    "\n",
    "        # Ustalenie rozmiarów obrazu za pomocą PIL\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "        # Tworzenie pliku PDF\n",
    "        pdf_path = os.path.join(pdf_directory, filename.replace('.png', '.pdf'))\n",
    "        c = canvas.Canvas(pdf_path, pagesize=(width, height))\n",
    "        c.drawImage(ImageReader(image_path), 0, 0, width=width, height=height)\n",
    "\n",
    "        # Dodawanie linku\n",
    "        link = \"https://open.spotify.com/track/\" + filename.replace('.csv.png', '')\n",
    "        c.linkURL(link, (0, 0, width, height), relative=1)\n",
    "\n",
    "        c.save()\n",
    "\n",
    "print(\"Pliki PDF zostały wygenerowane i zapisane.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
